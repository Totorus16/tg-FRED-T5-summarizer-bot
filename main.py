import torch
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from typing import List, Dict, Optional
from datetime import datetime, date
from transformers import GPT2Tokenizer, T5ForConditionalGeneration
import pytz

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∑–æ–Ω—ã
IRKUTSK_TZ = pytz.timezone('Asia/Irkutsk')
UTC_TZ = pytz.UTC
messages_storage: Dict[int, List[Dict]] = {}

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
device = torch.device('cuda')
model_name = "RussianNLP/FRED-T5-Summarizer"

print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {model_name} –Ω–∞ {device}...")
tokenizer = GPT2Tokenizer.from_pretrained(model_name, eos_token='</s>')
model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)
model.eval()
print("–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")


async def generate_with_prompt(chat_id: int, prompt_prefix: str, max_new_tokens: int = 300, min_new_tokens: int = 50) -> str:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ –º–æ–¥–µ–ª—å—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞.
    prompt_prefix ‚Äî –Ω–∞—á–∞–ª–æ –ø—Ä–æ–º–ø—Ç–∞ (–±–µ–∑ –¥–∏–∞–ª–æ–≥–∞), –Ω–∞–ø—Ä–∏–º–µ—Ä: "<LM> –ü–µ—Ä–µ—Å–∫–∞–∂–∏ –¥–∏–∞–ª–æ–≥ –ø–æ–¥—Ä–æ–±–Ω–æ.\n"
    """
    dialog = get_dialog_text(chat_id)
    if not dialog:
        return "–ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."

    input_text = prompt_prefix + dialog
    input_ids = torch.tensor([tokenizer.encode(input_text)]).to(device)

    with torch.no_grad():
        outputs = model.generate(
            input_ids,
            eos_token_id=tokenizer.eos_token_id,
            num_beams=5,
            max_new_tokens=max_new_tokens,
            min_new_tokens=min_new_tokens,
            length_penalty=0.6,
            early_stopping=False,
            no_repeat_ngram_size=3,
            do_sample=True,
            top_p=0.92,
            temperature=0.8,
            repetition_penalty=1.1
        )

    result = tokenizer.decode(outputs[0][1:], skip_special_tokens=True)
    return result

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    if chat_id not in messages_storage:
        messages_storage[chat_id] = []
    await update.message.reply_text(
        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–∞–ª–æ–≥–æ–≤.\n"
        "/log ‚Äî –ø–æ–¥—Ä–æ–±–Ω—ã–π –ø–µ—Ä–µ—Å–∫–∞–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π\n""
        "/clear ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é"
    )

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message or not update.message.text:
        return
    chat_id = update.effective_chat.id
    if chat_id not in messages_storage:
        messages_storage[chat_id] = []
    messages_storage[chat_id].append({
        'name': update.effective_user.first_name,
        'text': update.message.text,
        #'time': format_telegram_date(update.message.date)
    })

async def log_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    if chat_id not in messages_storage or not messages_storage[chat_id]:
        await update.message.reply_text("üì≠ –ò—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞")
        return

    processing_msg = await update.message.reply_text("‚è≥ –°–æ—Å—Ç–∞–≤–ª—è—é –ø–æ–¥—Ä–æ–±–Ω—ã–π –ø–µ—Ä–µ—Å–∫–∞–∑...")
    try:
        prompt = "<LM> –ü–µ—Ä–µ—Å–∫–∞–∂–∏ –¥–∏–∞–ª–æ–≥ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–¥—Ä–æ–±–Ω–æ, —Å–æ—Ö—Ä–∞–Ω—è—è –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã, –∏–º–µ–Ω–∞ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –∏ –∏—Ö –¥–µ–π—Å—Ç–≤–∏—è. –ù–µ —É–ø—É—Å–∫–∞–π –¥–µ—Ç–∞–ª–∏.\n"
        summary = await generate_with_prompt(chat_id, prompt, max_new_tokens=512, min_new_tokens=64)
        msg_count = len(messages_storage[chat_id])
        await processing_msg.edit_text(
            f"üìã **–ü–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–∞:**\n\n{summary}\n\n---\n*–°–æ–æ–±—â–µ–Ω–∏–π –≤ –∏—Å—Ç–æ—Ä–∏–∏: {msg_count}*"
        )
    except Exception as e:
        await processing_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")

async def clear_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    if chat_id in messages_storage:
        messages_storage[chat_id] = []
        await update.message.reply_text("üßπ –ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞")
    else:
        await update.message.reply_text("üì≠ –ò—Å—Ç–æ—Ä–∏—è –∏ —Ç–∞–∫ –ø—É—Å—Ç–∞")

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await start(update, context)  # –ø—Ä–æ—Å—Ç–æ –≤—ã–∑—ã–≤–∞–µ–º start

def start_bot():
    application = Application.builder().token("BOT-TOKEN").build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("log", log_command))
    #application.add_handler(CommandHandler("topics", topics_command))
    #application.add_handler(CommandHandler("ask", ask_command))
    application.add_handler(CommandHandler("clear", clear_command))
    #application.add_handler(CommandHandler("help", help_command))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...")
    application.run_polling()

def get_dialog_text(chat_id: int) -> Optional[str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ (–∏–º—è: —Å–æ–æ–±—â–µ–Ω–∏–µ) –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —á–∞—Ç–∞.
    """
    if chat_id not in messages_storage or not messages_storage[chat_id]:
        return None

    msgs = messages_storage[chat_id]

    if not msgs:
        return None

    dialog = "\n".join([f"{m['name']}: {m['text']}" for m in msgs])
    return dialog


start_bot()